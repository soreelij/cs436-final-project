{"cells":[{"cell_type":"markdown","metadata":{"id":"qEsNHTtVlbkV"},"source":["# **fast-DreamBooth colab From https://github.com/TheLastBen/fast-stable-diffusion, if you face any issues, feel free to discuss them.** \n","Keep your notebook updated for best experience. [Support](https://ko-fi.com/thelastben)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77925,"status":"ok","timestamp":1680552310476,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"fO-LfTShPVNr","outputId":"f2ad8a47-2d82-43ea-985b-64c83d089ff7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu117\n","Collecting torch==2.0.0+cu117\n","  Downloading https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp39-cp39-linux_x86_64.whl (1843.9 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1843920896 bytes == 0x35ca000 @  0x7fefc38361e7 0x6e6e9e 0x629594 0x685a9c 0x564b38 0x564bcf 0x53f72a 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c1d3 0x62c60f 0x5ab826 0x62c994 0x5ac335 0x62c994 0x5ab826 0x62c994 0x548478 0x537b6a 0x6a2ad6 0x5afd01 0x62c1d3\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2304901120 bytes == 0x7144a000 @  0x7fefc3837615 0x629504 0x685a9c 0x564b38 0x564bcf 0x53f72a 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c994 0x5ab826 0x62c1d3 0x62c60f 0x5ab826 0x62c994 0x5ac335 0x62c994 0x5ab826 0x62c994 0x548478 0x537b6a 0x6a2ad6 0x5afd01 0x62c1d3 0x5482c4\n","tcmalloc: large alloc 1843920896 bytes == 0x35ca000 @  0x7fefc38361e7 0x62e9b6 0x630070 0x53f72a 0x5ab826 0x62c994 0x5ab826 0x62c994 0x548478 0x537b6a 0x6a2ad6 0x5afd01 0x62c1d3 0x5482c4 0x5afd01 0x5a9eb4 0x5483e1 0x5afd01 0x5a9eb4 0x5483e1 0x5ac335 0x53d523 0x5abacc 0x53d523 0x5abacc 0x53d523 0x5abacc 0x62c1d3 0x62c60f 0x62bdf9 0x62bf2a\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m879.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==2.0.0+cu118 (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.8.2, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.11.0, 0.11.1, 0.11.2, 0.11.3, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.0+cu117, 0.14.1, 0.14.1+cu117, 0.15.0, 0.15.0+cu117, 0.15.1, 0.15.1+cu117)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==2.0.0+cu118\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2365,"status":"ok","timestamp":1680551625556,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"3rXUBFk-Oqqq","outputId":"12b50454-ebec-4390-f0f2-47c2a690538e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Package                       Version              Editable project location\n","----------------------------- -------------------- --------------------------------------\n","absl-py                       1.4.0\n","accelerate                    0.12.0\n","addict                        2.4.0\n","aenum                         3.1.11\n","aiofiles                      22.1.0\n","aiohttp                       3.8.4\n","aiosignal                     1.3.1\n","alabaster                     0.7.13\n","albumentations                1.2.1\n","altair                        4.2.2\n","analytics-python              1.4.0\n","antlr4-python3-runtime        4.9.3\n","anyio                         3.6.2\n","appdirs                       1.4.4\n","argon2-cffi                   21.3.0\n","argon2-cffi-bindings          21.2.0\n","arviz                         0.15.1\n","astropy                       5.2.2\n","astunparse                    1.6.3\n","async-timeout                 4.0.2\n","attrs                         22.2.0\n","audioread                     3.0.0\n","autograd                      1.5\n","av                            10.0.0\n","Babel                         2.12.1\n","backcall                      0.2.0\n","backoff                       1.10.0\n","basicsr                       1.4.2\n","bcrypt                        4.0.1\n","beautifulsoup4                4.11.2\n","bitsandbytes                  0.35.0\n","bleach                        6.0.0\n","blendmodes                    2022\n","blis                          0.7.9\n","bokeh                         2.4.3\n","boltons                       21.0.0\n","branca                        0.6.0\n","CacheControl                  0.12.11\n","cached-property               1.5.2\n","cachetools                    5.3.0\n","catalogue                     2.0.8\n","certifi                       2022.12.7\n","cffi                          1.15.1\n","chardet                       4.0.0\n","charset-normalizer            3.1.0\n","chex                          0.1.7\n","clean-fid                     0.1.31\n","click                         8.1.3\n","clip                          1.0\n","clip-anytorch                 2.5.0\n","cloudpickle                   2.2.1\n","cmake                         3.25.2\n","cmdstanpy                     1.1.0\n","colorcet                      3.0.1\n","coloredlogs                   15.0.1\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","confection                    0.0.4\n","cons                          0.4.5\n","contextlib2                   0.6.0.post1\n","contourpy                     1.0.7\n","convertdate                   2.4.0\n","cryptography                  40.0.1\n","cssselect2                    0.7.0\n","cufflinks                     0.17.3\n","cupy-cuda11x                  11.0.0\n","cvxopt                        1.3.0\n","cvxpy                         1.3.1\n","cycler                        0.11.0\n","cymem                         2.0.7\n","Cython                        0.29.33\n","dask                          2022.12.1\n","datascience                   0.17.6\n","db-dtypes                     1.0.5\n","dbus-python                   1.2.16\n","debugpy                       1.6.6\n","decorator                     4.4.2\n","deepdanbooru                  1.0.0\n","defusedxml                    0.7.1\n","deprecation                   2.1.0\n","diffusers                     0.15.0.dev0\n","distributed                   2022.12.1\n","dlib                          19.24.1\n","dm-tree                       0.1.8\n","docker-pycreds                0.4.0\n","docutils                      0.16\n","dopamine-rl                   4.0.6\n","dynamicprompts                0.10.2\n","earthengine-api               0.1.346\n","easydict                      1.10\n","ecos                          2.0.12\n","editdistance                  0.6.2\n","einops                        0.5.0\n","en-core-web-sm                3.5.0\n","entrypoints                   0.4\n","ephem                         4.1.4\n","et-xmlfile                    1.1.0\n","etils                         1.1.1\n","etuples                       0.3.8\n","exceptiongroup                1.1.1\n","facexlib                      0.2.5\n","fairscale                     0.4.4\n","fastai                        2.7.12\n","fastapi                       0.88.0\n","fastcore                      1.5.29\n","fastdownload                  0.0.7\n","fastjsonschema                2.16.3\n","fastprogress                  1.0.3\n","fastrlock                     0.8.1\n","ffmpy                         0.3.0\n","filelock                      3.10.7\n","filterpy                      1.4.5\n","fire                          0.4.0\n","firebase-admin                5.3.0\n","Flask                         2.2.3\n","flatbuffers                   23.3.3\n","flax                          0.6.8\n","folium                        0.14.0\n","font-roboto                   0.0.1\n","fonts                         0.0.3\n","fonttools                     4.39.3\n","freetype-py                   2.3.0\n","frozendict                    2.3.6\n","frozenlist                    1.3.3\n","fsspec                        2023.3.0\n","ftfy                          6.1.1\n","future                        0.18.3\n","gast                          0.4.0\n","GDAL                          3.3.2\n","gdown                         4.6.6\n","gensim                        4.3.1\n","geographiclib                 2.0\n","geopy                         2.3.0\n","gfpgan                        1.3.8                /usr/local/lib/python3.9/dist-packages\n","gin-config                    0.5.0\n","gitdb                         4.0.9\n","GitPython                     3.1.27\n","glob2                         0.7\n","google                        2.0.3\n","google-api-core               2.11.0\n","google-api-python-client      2.70.0\n","google-auth                   2.17.0\n","google-auth-httplib2          0.1.0\n","google-auth-oauthlib          0.4.6\n","google-cloud-bigquery         3.4.2\n","google-cloud-bigquery-storage 2.19.1\n","google-cloud-core             2.3.2\n","google-cloud-datastore        2.11.1\n","google-cloud-firestore        2.7.3\n","google-cloud-language         2.6.1\n","google-cloud-storage          2.7.0\n","google-cloud-translate        3.8.4\n","google-colab                  1.0.0\n","google-crc32c                 1.5.0\n","google-pasta                  0.2.0\n","google-resumable-media        2.4.1\n","googleapis-common-protos      1.59.0\n","googledrivedownloader         0.4\n","gradio                        3.16.2\n","graphviz                      0.20.1\n","greenlet                      2.0.2\n","grpcio                        1.53.0\n","grpcio-status                 1.48.2\n","gspread                       3.4.2\n","gspread-dataframe             3.0.8\n","gym                           0.25.2\n","gym-notices                   0.0.8\n","h11                           0.12.0\n","h5netcdf                      1.1.0\n","h5py                          3.8.0\n","HeapDict                      1.0.1\n","hijri-converter               2.2.4\n","holidays                      0.21.13\n","holoviews                     1.15.4\n","hsluv                         5.0.3\n","html5lib                      1.1\n","htmlmin                       0.1.12\n","httpcore                      0.15.0\n","httpimport                    1.3.0\n","httplib2                      0.21.0\n","httpx                         0.23.1\n","huggingface-hub               0.13.3\n","humanfriendly                 10.0\n","humanize                      4.6.0\n","hyperopt                      0.2.7\n","idna                          3.4\n","ImageHash                     4.3.1\n","imageio                       2.25.1\n","imageio-ffmpeg                0.4.8\n","imagesize                     1.4.1\n","imbalanced-learn              0.10.1\n","imgaug                        0.4.0\n","importlib-metadata            6.1.0\n","importlib-resources           5.12.0\n","imutils                       0.5.4\n","inflect                       6.0.2\n","inflection                    0.5.1\n","iniconfig                     2.0.0\n","intel-openmp                  2023.0.0\n","ipykernel                     5.5.6\n","ipython                       7.34.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.4.1\n","ipywidgets                    7.7.1\n","itsdangerous                  2.1.2\n","jax                           0.4.7\n","jaxlib                        0.4.7+cuda11.cudnn86\n","jieba                         0.42.1\n","Jinja2                        3.1.2\n","joblib                        1.1.1\n","jsonmerge                     1.8.0\n","jsonpickle                    3.0.1\n","jsonschema                    4.3.3\n","jupyter-client                6.1.12\n","jupyter-console               6.1.0\n","jupyter_core                  5.3.0\n","jupyterlab-pygments           0.2.2\n","jupyterlab-widgets            3.0.7\n","kaggle                        1.5.13\n","keras                         2.12.0\n","keras-vis                     0.4.1\n","kiwisolver                    1.4.4\n","korean-lunar-calendar         0.3.1\n","kornia                        0.6.0\n","langcodes                     3.3.0\n","lark                          1.1.2\n","lazy_loader                   0.2\n","libclang                      16.0.0\n","librosa                       0.10.0.post2\n","lightgbm                      3.3.5\n","lightning-utilities           0.3.0\n","linkify-it-py                 1.0.3\n","lit                           16.0.0\n","llvmlite                      0.39.1\n","locket                        1.0.0\n","logical-unification           0.4.5\n","lpips                         0.1.4\n","LunarCalendar                 0.0.9\n","lxml                          4.9.2\n","Markdown                      3.4.3\n","markdown-it-py                2.2.0\n","MarkupSafe                    2.1.2\n","matplotlib                    3.7.1\n","matplotlib-inline             0.1.6\n","matplotlib-venn               0.11.9\n","mdit-py-plugins               0.3.1\n","mdurl                         0.1.2\n","mediapipe                     0.9.0.1\n","miniKanren                    1.0.3\n","missingno                     0.5.2\n","mistune                       0.8.4\n","mizani                        0.8.1\n","mkl                           2019.0\n","ml-dtypes                     0.0.4\n","mlxtend                       0.14.0\n","monotonic                     1.6\n","more-itertools                9.1.0\n","moviepy                       1.0.3\n","mpmath                        1.3.0\n","msgpack                       1.0.5\n","multidict                     6.0.4\n","multimethod                   1.9.1\n","multipledispatch              0.6.0\n","multitasking                  0.0.11\n","murmurhash                    1.0.9\n","music21                       8.1.0\n","mypy-extensions               0.4.3\n","natsort                       8.3.1\n","nbclient                      0.7.2\n","nbconvert                     6.5.4\n","nbformat                      5.8.0\n","nest-asyncio                  1.5.6\n","networkx                      3.0\n","nibabel                       3.0.2\n","nltk                          3.8.1\n","notebook                      6.3.0\n","numba                         0.56.4\n","numexpr                       2.8.4\n","numpy                         1.22.4\n","oauth2client                  4.1.3\n","oauthlib                      3.2.2\n","omegaconf                     2.2.3\n","onnxruntime                   1.14.1\n","open-clip-torch               2.7.0\n","opencv-contrib-python         4.7.0.72\n","opencv-python                 4.7.0.72\n","opencv-python-headless        4.7.0.72\n","openpyxl                      3.0.10\n","opt-einsum                    3.3.0\n","optax                         0.1.4\n","orbax                         0.1.6\n","orjson                        3.8.7\n","osqp                          0.6.2.post0\n","packaging                     23.0\n","palettable                    3.3.0\n","pandas                        1.4.4\n","pandas-datareader             0.10.0\n","pandas-gbq                    0.17.9\n","pandas-profiling              3.2.0\n","pandocfilters                 1.5.0\n","panel                         0.14.4\n","param                         1.13.0\n","paramiko                      2.12.0\n","parso                         0.8.3\n","partd                         1.3.0\n","pathlib                       1.0.1\n","pathtools                     0.1.2\n","pathy                         0.10.1\n","patsy                         0.5.3\n","pep517                        0.13.0\n","pexpect                       4.8.0\n","phik                          0.12.3\n","pickleshare                   0.7.5\n","piexif                        1.1.3\n","Pillow                        8.4.0\n","PIMS                          0.6.1\n","pip                           22.0.4\n","pip-tools                     6.6.2\n","platformdirs                  3.2.0\n","plotly                        5.13.1\n","plotnine                      0.10.1\n","pluggy                        1.0.0\n","pooch                         1.6.0\n","portpicker                    1.3.9\n","prefetch-generator            1.0.3\n","preshed                       3.0.8\n","prettytable                   0.7.2\n","proglog                       0.1.10\n","progressbar2                  4.2.0\n","prometheus-client             0.16.0\n","promise                       2.3\n","prompt-toolkit                3.0.38\n","prophet                       1.1.2\n","proto-plus                    1.22.2\n","protobuf                      3.20.3\n","psutil                        5.9.4\n","psycopg2                      2.9.5\n","ptyprocess                    0.7.0\n","pudb                          2019.2\n","py4j                          0.10.9.7\n","pyarrow                       9.0.0\n","pyasn1                        0.4.8\n","pyasn1-modules                0.2.8\n","pycocoevalcap                 1.2\n","pycocotools                   2.0.6\n","pycparser                     2.21\n","pycryptodome                  3.16.0\n","pyct                          0.5.0\n","pydantic                      1.10.7\n","pydata-google-auth            1.7.0\n","pyDeprecate                   0.3.2\n","pydot                         1.4.2\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pydub                         0.25.1\n","pyerfa                        2.0.0.3\n","pyfiglet                      0.8.post1\n","pygame                        2.3.0\n","Pygments                      2.14.0\n","PyGObject                     3.36.0\n","PyMatting                     1.1.8\n","pymc                          5.1.2\n","PyMeeus                       0.5.12\n","pymystem3                     0.2.0\n","PyNaCl                        1.5.0\n","pyngrok                       5.2.1\n","pynvml                        11.4.1\n","PyOpenGL                      3.1.6\n","pyparsing                     3.0.9\n","PyQt5                         5.15.7\n","PyQt5-Qt5                     5.15.2\n","PyQt5-sip                     12.11.0\n","pyre-extensions               0.0.23\n","pyrsistent                    0.19.3\n","PySocks                       1.7.1\n","pytensor                      2.10.1\n","pytest                        7.2.2\n","python-apt                    0.0.0\n","python-dateutil               2.8.2\n","python-louvain                0.16\n","python-multipart              0.0.5\n","python-slugify                8.0.1\n","python-utils                  3.5.2\n","pytorch-lightning             1.7.7\n","pytz                          2022.7.1\n","pytz-deprecation-shim         0.1.0.post0\n","pyviz-comms                   2.2.1\n","PyWavelets                    1.4.1\n","PyYAML                        6.0\n","pyzmq                         23.2.1\n","qdldl                         0.1.5.post3\n","qudida                        0.0.4\n","realesrgan                    0.3.0                /usr/local/lib/python3.9/dist-packages\n","regex                         2022.10.31\n","rembg                         2.0.30\n","reportlab                     3.6.12\n","requests                      2.28.2\n","requests-oauthlib             1.3.1\n","requests-unixsocket           0.2.0\n","resize-right                  0.0.2\n","rfc3986                       1.5.0\n","rich                          13.3.3\n","rpy2                          3.5.5\n","rsa                           4.9\n","safetensors                   0.3.0\n","scikit-image                  0.19.3\n","scikit-learn                  1.2.2\n","scipy                         1.10.1\n","screen-resolution-extra       0.0.0\n","scs                           3.2.2\n","seaborn                       0.12.2\n","semantic-version              2.10.0\n","Send2Trash                    1.8.0\n","sentry-sdk                    1.9.10\n","setproctitle                  1.3.2\n","setuptools                    67.6.1\n","shapely                       2.0.1\n","shortuuid                     1.0.9\n","six                           1.16.0\n","sklearn-pandas                2.2.0\n","slicerator                    1.1.0\n","smart-open                    6.3.0\n","smmap                         5.0.0\n","sniffio                       1.3.0\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","soundfile                     0.12.1\n","soupsieve                     2.4\n","soxr                          0.3.4\n","spacy                         3.5.1\n","spacy-legacy                  3.0.12\n","spacy-loggers                 1.0.4\n","Sphinx                        3.5.4\n","sphinxcontrib-applehelp       1.0.4\n","sphinxcontrib-devhelp         1.0.2\n","sphinxcontrib-htmlhelp        2.0.1\n","sphinxcontrib-jsmath          1.0.1\n","sphinxcontrib-qthelp          1.0.3\n","sphinxcontrib-serializinghtml 1.1.5\n","SQLAlchemy                    1.4.47\n","sqlparse                      0.4.3\n","srsly                         2.4.6\n","starlette                     0.22.0\n","statsmodels                   0.13.5\n","svglib                        1.5.1\n","sympy                         1.11.1\n","tables                        3.7.0\n","tabulate                      0.8.10\n","tangled-up-in-unicode         0.2.0\n","tb-nightly                    2.11.0a20221004\n","tblib                         1.7.0\n","tenacity                      8.2.2\n","tensorboard                   2.12.0\n","tensorboard-data-server       0.7.0\n","tensorboard-plugin-wit        1.8.1\n","tensorboardX                  2.5.1\n","tensorflow                    2.12.0\n","tensorflow-datasets           4.8.3\n","tensorflow-estimator          2.12.0\n","tensorflow-gcs-config         2.12.0\n","tensorflow-hub                0.13.0\n","tensorflow-io                 0.32.0\n","tensorflow-io-gcs-filesystem  0.32.0\n","tensorflow-metadata           1.12.0\n","tensorflow-probability        0.19.0\n","tensorstore                   0.1.35\n","termcolor                     2.2.0\n","terminado                     0.17.1\n","text-unidecode                1.3\n","textblob                      0.17.1\n","tf-slim                       1.1.0\n","thinc                         8.1.9\n","threadpoolctl                 3.1.0\n","tifffile                      2023.3.21\n","timm                          0.6.12\n","tinycss2                      1.2.1\n","tokenizers                    0.12.1\n","toml                          0.10.2\n","tomli                         2.0.1\n","toolz                         0.12.0\n","torch                         2.0.0+cu118\n","torch-fidelity                0.3.0\n","torchaudio                    2.0.1+cu118\n","torchdata                     0.6.0\n","torchdiffeq                   0.2.3\n","torchmetrics                  0.10.3\n","torchsde                      0.2.5\n","torchsummary                  1.5.1\n","torchtext                     0.15.1\n","torchvision                   0.15.1+cu118\n","tornado                       6.2\n","tqdm                          4.65.0\n","traitlets                     5.7.1\n","trampoline                    0.1.2\n","transformers                  4.25.1\n","transforms3d                  0.2.1\n","triton                        2.0.0\n","tweepy                        4.13.0\n","typer                         0.7.0\n","typing_extensions             4.5.0\n","typing-inspect                0.8.0\n","tzdata                        2023.3\n","tzlocal                       4.3\n","uc-micro-py                   1.0.1\n","uritemplate                   4.1.1\n","urllib3                       1.26.15\n","urwid                         2.1.2\n","uvicorn                       0.20.0\n","vega-datasets                 0.9.0\n","visions                       0.7.4\n","vispy                         0.12.2\n","wandb                         0.13.3\n","wasabi                        1.1.1\n","wcwidth                       0.2.6\n","webcolors                     1.13\n","webencodings                  0.5.1\n","websockets                    10.4\n","Werkzeug                      2.2.3\n","wget                          3.2\n","wheel                         0.40.0\n","widgetsnbextension            3.6.4\n","wordcloud                     1.8.2.2\n","wrapt                         1.14.1\n","xarray                        2022.12.0\n","xarray-einstats               0.5.1\n","xformers                      0.0.18\n","xgboost                       1.7.4\n","xkit                          0.0.0\n","xlrd                          2.0.1\n","yapf                          0.32.0\n","yarl                          1.8.2\n","yellowbrick                   1.5\n","yfinance                      0.2.14\n","zict                          2.2.0\n","zipp                          3.15.0\n"]}],"source":["!pip3 list"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19591,"status":"ok","timestamp":1680556969298,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"A4Bae3VP6UsE","outputId":"2d8e91e7-76e3-4222-f17d-fee966dd0ae1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25134,"status":"ok","timestamp":1680557011512,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"QyvcqeiL65Tj","outputId":"fd6be2a5-388e-4140-d19e-58d02d315ae3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;32mInstalling dependencies...\n","\u001b[1;32mDone, proceed\n"]}],"source":["#@markdown # Dependencies\n","\n","from IPython.utils import capture\n","import time\n","import os\n","\n","print('\u001b[1;32mInstalling dependencies...')\n","with capture.capture_output() as cap:\n","    %cd /content/\n","    !pip install -qq --no-deps accelerate==0.12.0\n","    !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/dbdeps.txt\n","    !dpkg -i *.deb\n","    !tar -C / --zstd -xf gcolabdeps.tar.zst\n","    !rm *.deb | rm *.zst | rm *.txt\n","    !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n","    !wget -q -O /usr/local/lib/python3.9/dist-packages/flax/core/frozen_dict.py  https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/frozen_dict.py\n","    !pip install gradio==3.16.2 --no-deps -qq  \n","    %env LD_PRELOAD=libtcmalloc.so\n","    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","print('\u001b[1;32mDone, proceed')"]},{"cell_type":"markdown","metadata":{"id":"R3SsbIlxw66N"},"source":["# Model Download"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76522,"status":"ok","timestamp":1680552986652,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"O3KHGKqyeJp9","outputId":"f3eeeaae-98f9-4ba7-8735-53bf0718fe08"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;32mDONE !\n"]}],"source":["import os\n","import time\n","from IPython.utils import capture\n","from IPython.display import clear_output\n","import wget\n","\n","#@markdown - Skip this cell if you are loading a previous session that contains a trained model.\n","\n","#@markdown ---\n","\n","Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n","\n","#@markdown - Choose which version to finetune.\n","\n","with capture.capture_output() as cap: \n","  %cd /content/\n","\n","#@markdown ---\n","Custom_Model_Version=\"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n","\n","Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n","\n","#@markdown - Load and finetune a model from Hugging Face, must specify if v2, use the format \"profile/model\" like : runwayml/stable-diffusion-v1-5\n","#@markdown - If the custom model is private or requires a token, create token.txt containing the token in \"Fast-Dreambooth\" folder in your gdrive.\n","\n","CKPT_Path = \"\" #@param {type:\"string\"}\n","\n","CKPT_Link = \"\" #@param {type:\"string\"}\n","\n","safetensors = False #@param {type:\"boolean\"}\n","\n","sftnsr=\"\"\n","if not safetensors:\n","  modelnm=\"model.ckpt\"\n","else:\n","  modelnm=\"model.safetensors\"\n","  sftnsr=\"--from_safetensors\"\n","\n","if os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/token.txt'):\n","  with open(\"/content/gdrive/MyDrive/Fast-Dreambooth/token.txt\") as f:\n","     token = f.read()\n","  authe=f'https://USER:{token}@'\n","else:\n","  authe=\"https://\"\n","\n","def downloadmodel():\n","\n","  if os.path.exists('/content/stable-diffusion-v1-5'):\n","    !rm -r /content/stable-diffusion-v1-5\n","  clear_output()\n","\n","  %cd /content/\n","  clear_output()\n","  !mkdir /content/stable-diffusion-v1-5\n","  %cd /content/stable-diffusion-v1-5\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!vae/diffusion_pytorch_model.bin\\n!*.safetensors\" \u003e .git/info/sparse-checkout\n","  !git pull origin main\n","  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n","    !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n","    !rm -r .git\n","    !rm model_index.json\n","    time.sleep(1)    \n","    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n","    %cd /content/\n","    clear_output()\n","    print('\u001b[1;32mDONE !')\n","  else:\n","    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n","         print('\u001b[1;31mSomething went wrong')\n","         time.sleep(5)\n","\n","def newdownloadmodel():\n","\n","  %cd /content/\n","  clear_output()\n","  !mkdir /content/stable-diffusion-v2-768\n","  %cd /content/stable-diffusion-v2-768\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" \u003e .git/info/sparse-checkout\n","  !git pull origin main\n","  !rm -r /content/stable-diffusion-v2-768/.git\n","  %cd /content/\n","  clear_output()\n","  print('\u001b[1;32mDONE !')\n","\n","\n","def newdownloadmodelb():\n","\n","  %cd /content/\n","  clear_output()\n","  !mkdir /content/stable-diffusion-v2-512\n","  %cd /content/stable-diffusion-v2-512\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" \u003e .git/info/sparse-checkout\n","  !git pull origin main\n","  !rm -r /content/stable-diffusion-v2-512/.git\n","  %cd /content/\n","  clear_output()\n","  print('\u001b[1;32mDONE !')\n","\n","\n","if Path_to_HuggingFace != \"\":\n","  if Custom_Model_Version=='V2.1-512px' or Custom_Model_Version=='V2.1-768px':\n","    if os.path.exists('/content/stable-diffusion-custom'):\n","      !rm -r /content/stable-diffusion-custom\n","    clear_output()\n","    %cd /content/\n","    clear_output()\n","    !mkdir /content/stable-diffusion-custom\n","    %cd /content/stable-diffusion-custom\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" \u003e .git/info/sparse-checkout\n","    !git pull origin main\n","    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","      !rm -r /content/stable-diffusion-custom/.git\n","      %cd /content/ \n","      MODEL_NAME=\"/content/stable-diffusion-custom\"\n","      clear_output()\n","      print('\u001b[1;32mDONE !')\n","    else:\n","      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","            print('\u001b[1;31mCheck the link you provided')\n","            time.sleep(5)\n","  else:\n","    if os.path.exists('/content/stable-diffusion-custom'):\n","      !rm -r /content/stable-diffusion-custom\n","    clear_output()\n","    %cd /content/\n","    clear_output()\n","    !mkdir /content/stable-diffusion-custom\n","    %cd /content/stable-diffusion-custom\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" \u003e .git/info/sparse-checkout\n","    !git pull origin main\n","    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","      !rm -r /content/stable-diffusion-custom/.git\n","      !rm model_index.json\n","      time.sleep(1)\n","      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n","      %cd /content/ \n","      MODEL_NAME=\"/content/stable-diffusion-custom\"\n","      clear_output()\n","      print('\u001b[1;32mDONE !')\n","    else:\n","      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","            print('\u001b[1;31mCheck the link you provided')\n","            time.sleep(5)\n","\n","elif CKPT_Path !=\"\":\n","  %cd /content\n","  clear_output() \n","  if os.path.exists(str(CKPT_Path)):\n","    if Custom_Model_Version=='1.5':\n","      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n","      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $CKPT_Path --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n","      !rm /content/config.yaml\n","\n","    elif Custom_Model_Version=='V2.1-512px':\n","      !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n","      !python /content/convertodiff.py \"$CKPT_Path\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n","      !rm /content/convertodiff.py\n","\n","    elif Custom_Model_Version=='V2.1-768px':\n","      !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n","      !python /content/convertodiff.py \"$CKPT_Path\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n","      !rm /content/convertodiff.py\n","\n","\n","    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","      clear_output()\n","      MODEL_NAME=\"/content/stable-diffusion-custom\"\n","      print('\u001b[1;32mDONE !')\n","    else:\n","      !rm -r /content/stable-diffusion-custom\n","      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","        print('\u001b[1;31mConversion error')\n","        time.sleep(5)\n","  else:\n","    while not os.path.exists(str(CKPT_Path)):\n","       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n","       time.sleep(5)\n","\n","elif CKPT_Link !=\"\":\n","    %cd /content\n","    clear_output()\n","    !gdown --fuzzy -O $modelnm \"$CKPT_Link\"\n","    clear_output() \n","    if os.path.exists(modelnm):\n","      if os.path.getsize(modelnm) \u003e 1810671599:\n","        if Custom_Model_Version=='1.5':\n","          !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n","          !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $modelnm --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n","          !rm config.yaml\n","\n","        elif Custom_Model_Version=='V2.1-512px':\n","          !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n","          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n","          !rm convertodiff.py\n","\n","        elif Custom_Model_Version=='V2.1-768px':\n","          !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n","          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n","          !rm convertodiff.py\n","\n","\n","        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","          clear_output()\n","          MODEL_NAME=\"/content/stable-diffusion-custom\"\n","          print('\u001b[1;32mDONE !')\n","        else:\n","          !rm -r stable-diffusion-custom\n","          !rm $modelnm\n","          while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","            print('\u001b[1;31mConversion error')\n","            time.sleep(5)\n","      else:\n","        while os.path.getsize(modelnm) \u003c 1810671599:\n","           print('\u001b[1;31mWrong link, check that the link is valid')\n","           time.sleep(5)\n","\n","else:\n","  if Model_Version==\"1.5\":\n","    if not os.path.exists('/content/stable-diffusion-v1-5'):\n","      downloadmodel()\n","      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n","    else:\n","      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n","      print(\"\u001b[1;32mThe v1.5 model already exists, using this model.\")\n","  elif Model_Version==\"V2.1-512px\":\n","    if not os.path.exists('/content/stable-diffusion-v2-512'):\n","      newdownloadmodelb()\n","      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n","    else:\n","      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n","      print(\"\u001b[1;32mThe v2-512px model already exists, using this model.\")\n","  elif Model_Version==\"V2.1-768px\":\n","    if not os.path.exists('/content/stable-diffusion-v2-768'):\n","      newdownloadmodel()\n","      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n","    else:\n","      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n","      print(\"\u001b[1;32mThe v2-768px model already exists, using this model.\")"]},{"cell_type":"markdown","metadata":{"id":"0tN76Cj5P3RL"},"source":["# Dreambooth"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105323,"status":"ok","timestamp":1680557165670,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"A1B299g-_VJo","outputId":"9c923697-85d6-4f96-85ad-198c3b7ba2f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;32mSession loaded.\n"]}],"source":["import os\n","from IPython.display import clear_output\n","from IPython.utils import capture\n","from os import listdir\n","from os.path import isfile\n","import wget\n","import time\n","\n","#@markdown #Create/Load a Session\n","\n","try:\n","  MODEL_NAME\n","  pass\n","except:\n","  MODEL_NAME=\"\"\n","  \n","PT=\"\"\n","\n","Session_Name = \"AlbumCoverSession\" #@param{type: 'string'}\n","while Session_Name==\"\":\n","  print('\u001b[1;31mInput the Session Name:') \n","  Session_Name=input('')\n","Session_Name=Session_Name.replace(\" \",\"_\")\n","\n","#@markdown - Enter the session name, it if it exists, it will load it, otherwise it'll create an new session.\n","\n","Session_Link_optional = \"\" #@param{type: 'string'}\n","\n","#@markdown - Import a session from another gdrive, the shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove any intermediary CKPT if any.\n","\n","WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n","\n","if Session_Link_optional !=\"\":\n","  print('\u001b[1;32mDownloading session...')\n","  with capture.capture_output() as cap:\n","    %cd /content\n","    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n","      %mkdir -p $WORKSPACE'/Sessions'\n","      time.sleep(1)\n","    %cd $WORKSPACE'/Sessions'\n","    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n","    %cd $Session_Name\n","    !rm -r instance_images\n","    !unzip instance_images.zip\n","    !rm -r concept_images\n","    !unzip concept_images.zip\n","    !rm -r captions\n","    !unzip captions.zip\n","    %cd /content\n","\n","\n","INSTANCE_NAME=Session_Name\n","OUTPUT_DIR=\"/content/models/\"+Session_Name\n","SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n","INSTANCE_DIR=SESSION_DIR+'/instance_images'\n","CONCEPT_DIR=SESSION_DIR+'/concept_images'\n","CAPTIONS_DIR=SESSION_DIR+'/captions'\n","MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n","\n","Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n","#@markdown - Ignore this if you're not loading a previous session that contains a trained model\n","\n","\n","if os.path.exists(str(SESSION_DIR)):\n","  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n","  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):  \n","    \n","    def f(n):\n","      k=0\n","      for i in mdls:\n","        if k==n:\n","          !mv \"$SESSION_DIR/$i\" $MDLPTH\n","        k=k+1\n","\n","    k=0\n","    print('\u001b[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001b[1;34m')\n","\n","    for i in mdls:\n","      print(str(k)+'- '+i)\n","      k=k+1\n","    n=input()\n","    while int(n)\u003ek-1:\n","      n=input()\n","    if n!=\"000\":\n","      f(int(n))\n","      print('\u001b[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n","      time.sleep(2)\n","    else:\n","      print('\u001b[1;32mSkipping the intermediary checkpoints.')\n","    del n\n","\n","with capture.capture_output() as cap:\n","  %cd /content\n","  resume=False\n","\n","if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n","  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n","  if MODEL_NAME==\"\":\n","    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","  else:\n","    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n","\n","elif os.path.exists(MDLPTH):\n","  print('\u001b[1;32mSession found, loading the trained model ...')\n","  if Model_Version=='1.5':\n","    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n","    clear_output()\n","    print('\u001b[1;32mSession found, loading the trained model ...')\n","    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n","    !rm /content/config.yaml\n","\n","  elif Model_Version=='V2.1-512px':\n","    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n","    print('\u001b[1;32mSession found, loading the trained model ...')\n","    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n","    !rm /content/convertodiff.py\n","\n","  elif Model_Version=='V2.1-768px':\n","    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n","    print('\u001b[1;32mSession found, loading the trained model ...')\n","    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n","    !rm /content/convertodiff.py\n","  \n","  \n","  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","    resume=True\n","    clear_output()\n","    print('\u001b[1;32mSession loaded.')\n","  else:     \n","    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n","\n","elif not os.path.exists(str(SESSION_DIR)):\n","    %mkdir -p \"$INSTANCE_DIR\"\n","    print('\u001b[1;32mCreating session...')\n","    if MODEL_NAME==\"\":\n","      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","    else:\n","      print('\u001b[1;32mSession created, proceed to uploading instance images')\n","\n","    #@markdown\n","\n","    #@markdown # The most important step is to rename the instance pictures of each subject to a unique unknown identifier, example :\n","    #@markdown - If you have 10 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n","    #@markdown - Checkout this example : https://i.imgur.com/d2lD3rz.jpeg"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141357,"status":"ok","timestamp":1680553155727,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"LC4ukG60fgMy","outputId":"dc4bb58b-061b-4514-abe0-aa5d6e87e3c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["  |███████████████| 1001/1001 Uploaded\n"]},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1;32mDone, proceed to the next cell\n"]}],"source":["import shutil\n","from google.colab import files\n","import time\n","from PIL import Image\n","from tqdm import tqdm\n","import ipywidgets as widgets\n","from io import BytesIO\n","import wget\n","\n","with capture.capture_output() as cap:\n","  %cd /content\n","  if not os.path.exists(\"/content/smart_crop.py\"):\n","    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n","  from smart_crop import *\n","\n","#@markdown #Instance Images\n","#@markdown ----\n","\n","#@markdown\n","#@markdown - Run the cell to upload the instance pictures.\n","#@markdown - You can add `external captions` in txt files by simply giving each txt file the same name as the instance image, for example dikgur (1).jpg and dikgur (1).txt, and upload them here, to use the external captions, check the box \"external_captions\" in the training cell. `All the images must have one same extension` jpg or png or....etc\n","\n","Remove_existing_instance_images= True #@param{type: 'boolean'}\n","#@markdown - Uncheck the box to keep the existing instance images.\n","\n","if Remove_existing_instance_images:\n","  if os.path.exists(str(INSTANCE_DIR)):\n","    !rm -r \"$INSTANCE_DIR\"\n","  if os.path.exists(str(CAPTIONS_DIR)):\n","    !rm -r \"$CAPTIONS_DIR\"\n","\n","if not os.path.exists(str(INSTANCE_DIR)):\n","  %mkdir -p \"$INSTANCE_DIR\"\n","if not os.path.exists(str(CAPTIONS_DIR)):\n","  %mkdir -p \"$CAPTIONS_DIR\"\n","\n","if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n","  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n","\n","\n","IMAGES_FOLDER_OPTIONAL=\"/content/gdrive/MyDrive/image_data/data\" #@param{type: 'string'}\n","\n","#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n","\n","Smart_Crop_images= False #@param{type: 'boolean'}\n","Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n","\n","#@markdown - Smart crop the images without manual intervention.\n","\n","while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n","  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n","  IMAGES_FOLDER_OPTIONAL=input('')\n","\n","if IMAGES_FOLDER_OPTIONAL!=\"\":\n","  if os.path.exists(IMAGES_FOLDER_OPTIONAL+\"/.ipynb_checkpoints\"):\n","    %rm -r \"$IMAGES_FOLDER_OPTIONAL\"\"/.ipynb_checkpoints\"\n","\n","  with capture.capture_output() as cap:\n","    !mv $IMAGES_FOLDER_OPTIONAL/*.txt $CAPTIONS_DIR\n","  if Smart_Crop_images:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      extension = filename.split(\".\")[-1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n","      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):\n","        image=crop_image(file, Crop_size)\n","        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n","            image[0] = image[0].convert(\"RGB\")\n","            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image[0].save(new_path_with_file, format=extension.upper())\n","      else:\n","        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n","\n","  else:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n","\n","  print('\\n\u001b[1;32mDone, proceed to the next cell')\n","\n","\n","elif IMAGES_FOLDER_OPTIONAL ==\"\":\n","  up=\"\"\n","  uploaded = files.upload()\n","  for filename in uploaded.keys():\n","    if filename.split(\".\")[-1]==\"txt\":\n","      shutil.move(filename, CAPTIONS_DIR)\n","    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n","  if Smart_Crop_images:\n","    for filename in tqdm(up, bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, INSTANCE_DIR)\n","      extension = filename.split(\".\")[-1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n","      file = Image.open(new_path_with_file)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):\n","        image=crop_image(file, Crop_size)\n","        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n","            image[0] = image[0].convert(\"RGB\")\n","            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image[0].save(new_path_with_file, format=extension.upper())\n","      clear_output()\n","  else:\n","    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, INSTANCE_DIR)\n","      clear_output()\n","  print('\\n\u001b[1;32mDone, proceed to the next cell')\n","\n","with capture.capture_output() as cap:\n","  %cd \"$INSTANCE_DIR\"\n","  !find . -name \"* *\" -type f | rename 's/ /-/g'\n","  %cd \"$CAPTIONS_DIR\"\n","  !find . -name \"* *\" -type f | rename 's/ /-/g'\n","  \n","  %cd $SESSION_DIR\n","  !rm instance_images.zip captions.zip\n","  !zip -r instance_images instance_images\n","  !zip -r captions captions\n","  %cd /content"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1680542653216,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"Baw78R-w4T2j","outputId":"119a83cf-4f8c-4307-bfcf-7b8388f59398"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfcd9b831a4d46e88fca6e8b33ce572e","version_major":2,"version_minor":0},"text/plain":["HBox(children=(Select(options=('Select an instance image to caption', '10.jpg', '0.jpg', '100.jpg', '1000.jpg'…"]},"metadata":{},"output_type":"display_data"}],"source":["import ipywidgets as widgets\n","from io import BytesIO\n","#@markdown #Captions\n","\n","#@markdown - Open a tool to manually `create` captions or edit existing captions of the instance images.\n","\n","paths=\"\"\n","out=\"\"\n","widgets_l=\"\"\n","clear_output()\n","def Caption(path):\n","    if path!=\"Select an instance image to caption\":\n","      \n","      name = os.path.splitext(os.path.basename(path))[0]\n","      ext=os.path.splitext(os.path.basename(path))[-1][1:]\n","      if ext==\"jpg\" or \"JPG\":\n","        ext=\"JPEG\"      \n","\n","      if os.path.exists(CAPTIONS_DIR+\"/\"+name + '.txt'):\n","        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n","            text = f.read()\n","      else:\n","        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n","            f.write(\"\")\n","            with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n","                text = f.read()   \n","\n","      img=Image.open(os.path.join(INSTANCE_DIR,path))\n","      img=img.convert(\"RGB\")\n","      img=img.resize((420, 420))\n","      image_bytes = BytesIO()\n","      img.save(image_bytes, format=ext, qualiy=10)\n","      image_bytes.seek(0)\n","      image_data = image_bytes.read()\n","      img= image_data  \n","      image = widgets.Image(\n","          value=img,\n","          width=420,\n","          height=420\n","      )\n","      text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '300px', 'height': '120px'})\n","      \n","\n","      def update_text(text):\n","          with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n","              f.write(text)\n","\n","      button = widgets.Button(description='Save', button_style='success')\n","      button.on_click(lambda b: update_text(text_area.value))\n","\n","      return widgets.VBox([widgets.HBox([image, text_area, button])])\n","\n","\n","paths = os.listdir(INSTANCE_DIR)\n","widgets_l = widgets.Select(options=[\"Select an instance image to caption\"]+paths, rows=25)\n","\n","\n","out = widgets.Output()\n","\n","def click(change):\n","    with out:\n","        out.clear_output()\n","        display(Caption(change.new))\n","\n","widgets_l.observe(click, names='value')\n","display(widgets.HBox([widgets_l, out]))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"LxEv3u8mQos3"},"outputs":[],"source":["import shutil\n","from google.colab import files\n","from PIL import Image\n","from tqdm import tqdm\n","\n","#@markdown #Concept Images (Regularization)\n","#@markdown ----\n","\n","#@markdown\n","#@markdown - Run this `optional` cell to upload concept pictures. If you're traning on a specific face, skip this cell.\n","\n","Remove_existing_concept_images= True #@param{type: 'boolean'}\n","#@markdown - Uncheck the box to keep the existing concept images.\n","\n","if Remove_existing_concept_images:\n","  if os.path.exists(str(CONCEPT_DIR)):\n","    !rm -r \"$CONCEPT_DIR\"\n","\n","if not os.path.exists(str(CONCEPT_DIR)):\n","  %mkdir -p \"$CONCEPT_DIR\"\n","\n","IMAGES_FOLDER_OPTIONAL=\"\" #@param{type: 'string'}\n","\n","#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) concept images. Leave EMPTY to upload.\n","\n","Smart_Crop_images= True\n","Crop_size = 512\n","\n","while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n","  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n","  IMAGES_FOLDER_OPTIONAL=input('')\n","\n","if IMAGES_FOLDER_OPTIONAL!=\"\":\n","  if Smart_Crop_images:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      extension = filename.split(\".\")[-1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(CONCEPT_DIR, filename)\n","      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):\n","        image=crop_image(file, Crop_size)\n","        if extension.upper() == \"JPG\" or \"jpg\":\n","            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image[0].save(new_path_with_file, format=extension.upper())\n","      else:\n","        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$CONCEPT_DIR\"\n","\n","  else:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$CONCEPT_DIR\"\n","\n","elif IMAGES_FOLDER_OPTIONAL ==\"\":\n","  uploaded = files.upload()\n","  if Smart_Crop_images:\n","    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, CONCEPT_DIR)\n","      extension = filename.split(\".\")[-1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(CONCEPT_DIR, filename)\n","      file = Image.open(new_path_with_file)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):\n","        image=crop_image(file, Crop_size)\n","        if extension.upper() == \"JPG\" or \"jpg\":\n","            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image[0].save(new_path_with_file, format=extension.upper())\n","      clear_output()\n","  else:\n","    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, CONCEPT_DIR)\n","      clear_output()\n","\n","\n","print('\\n\u001b[1;32mAlmost done...')\n","with capture.capture_output() as cap:\n","  i=0\n","  for filename in os.listdir(CONCEPT_DIR):\n","    extension = filename.split(\".\")[-1]\n","    identifier=filename.split(\".\")[0]\n","    new_path_with_file = os.path.join(CONCEPT_DIR, \"conceptimagedb\"+str(i)+\".\"+extension)\n","    filepath=os.path.join(CONCEPT_DIR,filename)\n","    !mv \"$filepath\" $new_path_with_file\n","    i=i+1\n","\n","  %cd $SESSION_DIR\n","  !rm concept_images.zip\n","  !zip -r concept_images concept_images\n","  %cd /content\n","\n","print('\\n\u001b[1;32mDone, proceed to the training cell')"]},{"cell_type":"markdown","metadata":{"id":"ZnmQYfZilzY6"},"source":["# Training"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"elapsed":289,"status":"error","timestamp":1680556675651,"user":{"displayName":"Eli Sorensen","userId":"09298840334922747162"},"user_tz":360},"id":"1-9QbkfAVYYU","outputId":"3d2ca2e9-3422-48cb-8075-a56d99ac662d"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-4facc21732e6\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 10\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 10\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINSTANCE_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/.ipynb_checkpoints\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-r $INSTANCE_DIR\"/.ipynb_checkpoints\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'INSTANCE_DIR' is not defined"]}],"source":["#@markdown ---\n","#@markdown #Start DreamBooth\n","#@markdown ---\n","import os\n","from IPython.display import clear_output\n","from google.colab import runtime\n","import time\n","import random\n","\n","if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n","  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n","\n","if os.path.exists(CONCEPT_DIR+\"/.ipynb_checkpoints\"):\n","  %rm -r $CONCEPT_DIR\"/.ipynb_checkpoints\"\n","\n","if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n","  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n","\n","Resume_Training = False #@param {type:\"boolean\"}\n","\n","if resume and not Resume_Training:\n","  print('\u001b[1;31mOverwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n","  while True:\n","    ansres=input('')\n","    if ansres=='no':\n","      Resume_Training = True\n","      break\n","    elif ansres=='yes':\n","      Resume_Training = False\n","      resume= False\n","      break\n","\n","while not Resume_Training and MODEL_NAME==\"\":\n","  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","  time.sleep(5)\n","\n","#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n","\n","MODELT_NAME=MODEL_NAME\n","\n","UNet_Training_Steps=2000 #@param{type: 'number'}\n","UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n","untlr=UNet_Learning_Rate\n","\n","#@markdown - These default settings are for a dataset of 10 pictures which is enough for training a face, start with 1500 or lower, test the model, if not enough, resume training for 200 steps, keep testing until you get the desired output, `set it to 0 to train only the text_encoder`.\n","\n","Text_Encoder_Training_Steps=350 #@param{type: 'number'}\n","\n","#@markdown - 200-450 steps is enough for a small dataset, keep this number small to avoid overfitting, set to 0 to disable, `set it to 0 before resuming training if it is already trained`.\n","\n","Text_Encoder_Concept_Training_Steps=0 #@param{type: 'number'}\n","\n","#@markdown - Suitable for training a style/concept as it acts as heavy regularization, set it to 1500 steps for 200 concept images (you can go higher), set to 0 to disable, set both the settings above to 0 to fintune only the text_encoder on the concept, `set it to 0 before resuming training if it is already trained`.\n","\n","Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n","txlr=Text_Encoder_Learning_Rate\n","\n","#@markdown - Learning rate for both text_encoder and concept_text_encoder, keep it low to avoid overfitting (1e-6 is higher than 4e-7)\n","\n","trnonltxt=\"\"\n","if UNet_Training_Steps==0:\n","   trnonltxt=\"--train_only_text_encoder\"\n","\n","Seed=''\n","\n","ofstnse=\"\"\n","Offset_Noise = False #@param {type:\"boolean\"}\n","#@markdown - Always use it for style training.\n","\n","if Offset_Noise:\n","  ofstnse=\"--offset_noise\"\n","\n","External_Captions = True #@param {type:\"boolean\"}\n","#@markdown - Get the captions from a text file for each instance image.\n","extrnlcptn=\"\"\n","if External_Captions:\n","  extrnlcptn=\"--external_captions\"\n","\n","Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n","Res=int(Resolution)\n","\n","#@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger).\n","\n","fp16 = True\n","\n","if Seed =='' or Seed=='0':\n","  Seed=random.randint(1, 999999)\n","else:\n","  Seed=int(Seed)\n","\n","if fp16:\n","  prec=\"fp16\"\n","else:\n","  prec=\"no\"\n","\n","precision=prec\n","\n","resuming=\"\"\n","if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","  MODELT_NAME=OUTPUT_DIR\n","  print('\u001b[1;32mResuming Training...\u001b[0m')\n","  resuming=\"Yes\"\n","elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m')\n","  MODELT_NAME=MODEL_NAME\n","  while MODEL_NAME==\"\":\n","    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","    time.sleep(5)\n","\n","Enable_text_encoder_training= True\n","Enable_Text_Encoder_Concept_Training= True\n","\n","if Text_Encoder_Training_Steps==0 :\n","   Enable_text_encoder_training= False\n","else:\n","  stptxt=Text_Encoder_Training_Steps\n","\n","if Text_Encoder_Concept_Training_Steps==0:\n","   Enable_Text_Encoder_Concept_Training= False\n","else:\n","  stptxtc=Text_Encoder_Concept_Training_Steps\n","\n","#@markdown ---------------------------\n","Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n","Save_Checkpoint_Every=500 #@param{type: 'number'}\n","if Save_Checkpoint_Every==None:\n","  Save_Checkpoint_Every=1\n","#@markdown - Minimum 200 steps between each save.\n","stp=0\n","Start_saving_from_the_step=500 #@param{type: 'number'}\n","if Start_saving_from_the_step==None:\n","  Start_saving_from_the_step=0\n","if (Start_saving_from_the_step \u003c 200):\n","  Start_saving_from_the_step=Save_Checkpoint_Every\n","stpsv=Start_saving_from_the_step\n","if Save_Checkpoint_Every_n_Steps:\n","  stp=Save_Checkpoint_Every\n","#@markdown - Start saving intermediary checkpoints from this step.\n","\n","Disconnect_after_training=False #@param {type:\"boolean\"}\n","\n","#@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n","\n","def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n","    \n","    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n","    $trnonltxt \\\n","    $extrnlcptn \\\n","    $ofstnse \\\n","    --image_captions_filename \\\n","    --train_text_encoder \\\n","    --dump_only_text_encoder \\\n","    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n","    --instance_data_dir=\"$INSTANCE_DIR\" \\\n","    --output_dir=\"$OUTPUT_DIR\" \\\n","    --captions_dir=\"$CAPTIONS_DIR\" \\\n","    --instance_prompt=\"$PT\" \\\n","    --seed=$Seed \\\n","    --resolution=$Res \\\n","    --mixed_precision=$precision \\\n","    --train_batch_size=1 \\\n","    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n","    --use_8bit_adam \\\n","    --learning_rate=$txlr \\\n","    --lr_scheduler=\"linear\" \\\n","    --lr_warmup_steps=0 \\\n","    --max_train_steps=$Training_Steps\n","\n","def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n","    clear_output()\n","    if resuming==\"Yes\":\n","      print('\u001b[1;32mResuming Training...\u001b[0m')\n","    print('\u001b[1;33mTraining the UNet...\u001b[0m')\n","    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n","    $extrnlcptn \\\n","    $ofstnse \\\n","    --image_captions_filename \\\n","    --train_only_unet \\\n","    --save_starting_step=$stpsv \\\n","    --save_n_steps=$stp \\\n","    --Session_dir=$SESSION_DIR \\\n","    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n","    --instance_data_dir=\"$INSTANCE_DIR\" \\\n","    --output_dir=\"$OUTPUT_DIR\" \\\n","    --captions_dir=\"$CAPTIONS_DIR\" \\\n","    --instance_prompt=\"$PT\" \\\n","    --seed=$Seed \\\n","    --resolution=$Res \\\n","    --mixed_precision=$precision \\\n","    --train_batch_size=1 \\\n","    --gradient_accumulation_steps=1 \\\n","    --use_8bit_adam \\\n","    --learning_rate=$untlr \\\n","    --lr_scheduler=\"linear\" \\\n","    --lr_warmup_steps=0 \\\n","    --max_train_steps=$Training_Steps\n","\n","\n","if Enable_text_encoder_training :\n","  print('\u001b[1;33mTraining the text encoder...\u001b[0m')\n","  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n","    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n","  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n","\n","if Enable_Text_Encoder_Concept_Training:\n","  if os.path.exists(CONCEPT_DIR):\n","    if os.listdir(CONCEPT_DIR)!=[]:\n","      clear_output()\n","      if resuming==\"Yes\":\n","        print('\u001b[1;32mResuming Training...\u001b[0m')\n","      print('\u001b[1;33mTraining the text encoder on the concept...\u001b[0m')\n","      dump_only_textenc(trnonltxt, MODELT_NAME, CONCEPT_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxtc)\n","    else:\n","      clear_output()\n","      if resuming==\"Yes\":\n","        print('\u001b[1;32mResuming Training...\u001b[0m')\n","      print('\u001b[1;31mNo concept images found, skipping concept training...')\n","      Text_Encoder_Concept_Training_Steps=0\n","      time.sleep(8)\n","  else:\n","      clear_output()\n","      if resuming==\"Yes\":\n","        print('\u001b[1;32mResuming Training...\u001b[0m')\n","      print('\u001b[1;31mNo concept images found, skipping concept training...')\n","      Text_Encoder_Concept_Training_Steps=0\n","      time.sleep(8)\n","\n","if UNet_Training_Steps!=0:\n","  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n","\n","if UNet_Training_Steps==0 and Text_Encoder_Concept_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n","  print('\u001b[1;32mNothing to do')\n","else:\n","  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n","    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n","    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n","    clear_output()\n","    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n","      clear_output()\n","      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n","      if Disconnect_after_training :\n","        time.sleep(20)\n","        runtime.unassign()\n","    else:\n","      print(\"\u001b[1;31mSomething went wrong\")\n","  else:\n","    print(\"\u001b[1;31mSomething went wrong\")"]},{"cell_type":"markdown","metadata":{"id":"ehi1KKs-l-ZS"},"source":["# Test The Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"iAZGngFcI8hq"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n","  warnings.warn(\n","Loading weights [02668ea343] from /content/gdrive/MyDrive/Fast-Dreambooth/Sessions/AlbumCoverSession/AlbumCoverSession.ckpt\n","Creating model from config: /content/gdrive/MyDrive/sd/stable-diffusion-webui/configs/v1-inference.yaml\n","LatentDiffusion: Running in eps-prediction mode\n","DiffusionWrapper has 859.52 M params.\n","Applying xformers cross attention optimization.\n","Textual inversion embeddings loaded(0): \n","Model loaded in 32.1s (load weights from disk: 22.1s, create model: 4.8s, apply weights to model: 3.4s, apply half(): 1.0s, move model to device: 0.8s).\n","Running on public URL: https://7a982486-44f4-445a.gradio.live\n","\u001b[32m✔ Connected\n","Startup time: 124.9s (import gradio: 3.1s, import ldm: 10.0s, other imports: 50.0s, list SD models: 0.5s, setup codeformer: 9.8s, list builtin upscalers: 1.2s, load scripts: 13.1s, load SD checkpoint: 32.1s, create ui: 1.7s, gradio launch: 2.2s, scripts app_started_callback: 1.1s).\n","100% 20/20 [00:08\u003c00:00,  2.33it/s]\n","100% 20/20 [00:03\u003c00:00,  6.10it/s]\n","100% 20/20 [00:03\u003c00:00,  6.30it/s]\n","100% 20/20 [00:03\u003c00:00,  6.22it/s]\n","100% 20/20 [00:03\u003c00:00,  6.16it/s]\n","100% 20/20 [00:03\u003c00:00,  6.27it/s]\n","100% 20/20 [00:03\u003c00:00,  6.12it/s]\n","100% 20/20 [00:03\u003c00:00,  6.18it/s]\n","100% 20/20 [00:03\u003c00:00,  6.41it/s]\n","100% 20/20 [00:03\u003c00:00,  6.13it/s]\n","100% 20/20 [00:03\u003c00:00,  6.22it/s]\n","100% 20/20 [00:03\u003c00:00,  6.27it/s]\n","100% 20/20 [00:03\u003c00:00,  6.20it/s]\n","100% 20/20 [00:03\u003c00:00,  6.20it/s]\n","100% 20/20 [00:03\u003c00:00,  6.28it/s]\n","100% 20/20 [00:03\u003c00:00,  6.07it/s]\n","100% 20/20 [00:03\u003c00:00,  6.24it/s]\n","100% 20/20 [00:03\u003c00:00,  6.15it/s]\n","100% 20/20 [00:03\u003c00:00,  6.36it/s]\n","100% 20/20 [00:03\u003c00:00,  6.48it/s]\n","100% 20/20 [00:03\u003c00:00,  6.31it/s]\n","100% 20/20 [00:03\u003c00:00,  6.47it/s]\n","100% 20/20 [00:03\u003c00:00,  6.30it/s]\n","100% 20/20 [00:03\u003c00:00,  6.26it/s]\n","100% 20/20 [00:03\u003c00:00,  6.21it/s]\n","100% 20/20 [00:03\u003c00:00,  6.21it/s]\n","100% 20/20 [00:03\u003c00:00,  6.23it/s]\n","100% 20/20 [00:03\u003c00:00,  6.16it/s]\n","100% 20/20 [00:03\u003c00:00,  6.25it/s]\n","100% 20/20 [00:03\u003c00:00,  6.20it/s]\n","100% 20/20 [00:03\u003c00:00,  6.12it/s]\n","100% 20/20 [00:03\u003c00:00,  6.16it/s]\n","100% 20/20 [00:03\u003c00:00,  6.27it/s]\n","100% 20/20 [00:03\u003c00:00,  6.27it/s]\n","100% 20/20 [00:03\u003c00:00,  6.29it/s]\n","100% 20/20 [00:03\u003c00:00,  6.22it/s]\n"]}],"source":["import os\n","import time\n","import sys\n","import fileinput\n","from IPython.display import clear_output\n","from subprocess import getoutput\n","from IPython.utils import capture\n","from pyngrok import ngrok, conf\n","\n","\n","Previous_Session=\"\" #@param{type: 'string'}\n","\n","#@markdown - Leave empty if you want to use the current trained model.\n","\n","Use_Custom_Path = False #@param {type:\"boolean\"}\n","\n","try:\n","  INSTANCE_NAME\n","  INSTANCET=INSTANCE_NAME\n","except:\n","  pass\n","#@markdown - if checked, an input box will ask the full path to a desired model.\n","\n","if Previous_Session!=\"\":\n","  INSTANCET=Previous_Session\n","  INSTANCET=INSTANCET.replace(\" \",\"_\")\n","\n","if Use_Custom_Path:\n","  try:\n","    INSTANCET\n","    del INSTANCET\n","  except:\n","    pass\n","\n","try:\n","  INSTANCET\n","  if Previous_Session!=\"\":\n","    path_to_trained_model='/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/'+Previous_Session+\"/\"+Previous_Session+'.ckpt'\n","  else:\n","    path_to_trained_model=SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n","except:\n","  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n","  path_to_trained_model=input()\n","     \n","while not os.path.exists(path_to_trained_model):\n","   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n","   path_to_trained_model=input()\n","   \n","fgitclone = \"git clone --depth 1\"\n","\n","with capture.capture_output() as cap:\n","    if not os.path.exists('/content/gdrive/MyDrive'):\n","      !mkdir -p /content/gdrive/MyDrive\n","\n","if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion'):\n","    !wget -q -O /content/sd_rep.tar.zst https://huggingface.co/TheLastBen/dependencies/resolve/main/sd_rep.tar.zst\n","    !tar -C  /content/gdrive/MyDrive --zstd -xf /content/sd_rep.tar.zst\n","    !rm /content/sd_rep.tar.zst\n","    clear_output()\n","\n","with capture.capture_output() as cap:\n","  %cd /content/gdrive/MyDrive/sd\n","  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-webui\n","  %cd stable-diffusion-webui\n","  !mkdir cache\n","  !sed -i 's@~/.cache@/content/gdrive/MyDrive/sd/stable-diffusion-webui/cache@' /usr/local/lib/python3.9/dist-packages/transformers/utils/hub.py\n","\n","  clear_output()\n","  !git reset --hard\n","  time.sleep(1)\n","  !rm webui.sh\n","  !git pull\n","  !git fetch --unshallow\n","  !git checkout a9eab236d7e8afa4d6205127904a385b2c43bb24\n","  \n","with capture.capture_output() as cap:\n","  if not os.path.exists('/tools/node/bin/lt'):\n","    !npm install -g localtunnel\n","\n","Ngrok_token = \"\" #@param {type:\"string\"}\n","\n","#@markdown - Input your ngrok token if you want to use ngrok server.\n","\n","Use_localtunnel = False #@param {type:\"boolean\"}\n","\n","User = \"\" #@param {type:\"string\"}\n","Password= \"\" #@param {type:\"string\"}\n","#@markdown - Add credentials to your Gradio interface (optional).\n","\n","auth=f\"--gradio-auth {User}:{Password}\"\n","if User ==\"\" or Password==\"\":\n","  auth=\"\"\n","\n","with capture.capture_output() as cap:\n","  %cd modules\n","  !wget -q -O paths.py https://github.com/TheLastBen/fast-stable-diffusion/raw/5632d2ef7fffd940976538d270854ec4faf26855/AUTOMATIC1111_files/paths.py\n","  !wget -q -O extras.py https://github.com/AUTOMATIC1111/stable-diffusion-webui/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/extras.py\n","  !wget -q -O sd_models.py https://github.com/AUTOMATIC1111/stable-diffusion-webui/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/sd_models.py\n","  !wget -q -O /usr/local/lib/python3.9/dist-packages/gradio/blocks.py https://github.com/TheLastBen/fast-stable-diffusion/raw/7ff88eaa1fb4997bacd9845bd487f9a14335d625/AUTOMATIC1111_files/blocks.py\n","  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n","\n","  !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_models.py\n","  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n","  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/extras.py  \n","\n","share=''\n","if Ngrok_token!=\"\":\n","  ngrok.kill()\n","  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n","\n","  for line in fileinput.input('/usr/local/lib/python3.9/dist-packages/gradio/blocks.py', inplace=True):\n","    if line.strip().startswith('self.server_name ='):\n","        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n","    if line.strip().startswith('self.protocol = \"https\"'):\n","        line = '            self.protocol = \"https\"\\n'\n","    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n","        line = ''\n","    if line.strip().startswith('else \"http\"'):\n","        line = ''\n","    sys.stdout.write(line)\n","\n","elif Use_localtunnel:\n","  with capture.capture_output() as cap:\n","    share=''\n","    %cd /content\n","    !nohup lt --port 7860 \u003e srv.txt 2\u003e\u00261 \u0026\n","    time.sleep(2)\n","    !grep -o 'https[^ ]*' /content/srv.txt \u003esrvr.txt\n","    time.sleep(2)\n","    srv= getoutput('cat /content/srvr.txt')\n","\n","    for line in fileinput.input('/usr/local/lib/python3.9/dist-packages/gradio/blocks.py', inplace=True):\n","      if line.strip().startswith('self.server_name ='):\n","          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n","      if line.strip().startswith('self.protocol = \"https\"'):\n","          line = '            self.protocol = \"https\"\\n'\n","      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n","          line = ''\n","      if line.strip().startswith('else \"http\"'):\n","          line = ''\n","      sys.stdout.write(line)\n","            \n","    !rm /content/srv.txt /content/srvr.txt\n","    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n","\n","else:\n","  share='--share'\n","\n","configf=\"--api --disable-safe-unpickle --enable-insecure-extension-access --no-half-vae --xformers --no-download-sd-model --disable-console-progressbars\"\n","\n","clear_output()\n","\n","if os.path.isfile(path_to_trained_model):\n","  !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --ckpt \"$path_to_trained_model\" $auth $configf\n","else:\n","  !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --ckpt-dir \"$path_to_trained_model\" $auth $configf"]},{"cell_type":"markdown","metadata":{"id":"d_mQ23XsOc5R"},"source":["# Upload The Trained Model to Hugging Face "]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"NTqUIuhROdH4"},"outputs":[],"source":["from slugify import slugify\n","from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n","from huggingface_hub import create_repo\n","from IPython.display import display_markdown\n","from IPython.display import clear_output\n","from IPython.utils import capture\n","from google.colab import files\n","import shutil\n","import time\n","import os\n","\n","Upload_sample_images = False #@param {type:\"boolean\"}\n","#@markdown - Upload showcase images of your trained model\n","\n","Name_of_your_concept = \"\" #@param {type:\"string\"}\n","if(Name_of_your_concept == \"\"):\n","  Name_of_your_concept = Session_Name\n","Name_of_your_concept=Name_of_your_concept.replace(\" \",\"-\")  \n","  \n","#@markdown - [Create a write access token](https://huggingface.co/settings/tokens) , go to \"New token\" -\u003e Role : Write. A regular read token won't work here.\n","hf_token_write = \"\" #@param {type:\"string\"}\n","if hf_token_write ==\"\":\n","  print('\u001b[1;32mYour Hugging Face write access token : ')\n","  hf_token_write=input()\n","\n","hf_token = hf_token_write\n","\n","api = HfApi()\n","your_username = api.whoami(token=hf_token)[\"name\"]\n","\n","repo_id = f\"{your_username}/{slugify(Name_of_your_concept)}\"\n","output_dir = f'/content/models/'+INSTANCE_NAME\n","\n","def bar(prg):\n","    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n","    return br\n","\n","print(\"\u001b[1;32mLoading...\")\n","\n","NM=\"False\"\n","if os.path.getsize(OUTPUT_DIR+\"/text_encoder/pytorch_model.bin\") \u003e 670901463:\n","  NM=\"True\"\n","\n","with capture.capture_output() as cap:\n","  if NM==\"False\":\n","    %cd $OUTPUT_DIR\n","    !rm -r safety_checker feature_extractor .git\n","    !rm model_index.json\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" \u003e .git/info/sparse-checkout\n","    !git pull origin main\n","    !rm -r .git\n","    %cd /content\n","  else:\n","    %cd $OUTPUT_DIR\n","    !rm -r feature_extractor .git\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/stabilityai/stable-diffusion-2-1\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"feature_extractor\" \u003e .git/info/sparse-checkout\n","    !git pull origin main\n","    !rm -r .git\n","    %cd /content\n","\n","\n","image_string = \"\"\n","\n","if os.path.exists('/content/sample_images'):\n","  !rm -r /content/sample_images\n","Samples=\"/content/sample_images\"\n","!mkdir $Samples\n","clear_output()\n","\n","if Upload_sample_images:\n","\n","  print(\"\u001b[1;32mUpload Sample images of the model\")\n","  uploaded = files.upload()\n","  for filename in uploaded.keys():\n","    shutil.move(filename, Samples)\n","  %cd $Samples\n","  !find . -name \"* *\" -type f | rename 's/ /_/g'\n","  %cd /content\n","  clear_output()\n","\n","  print(bar(1))\n","\n","  images_upload = os.listdir(Samples)\n","  instance_prompt_list = []\n","  for i, image in enumerate(images_upload):\n","      image_string = f'''\n","  {image_string}![{i}](https://huggingface.co/{repo_id}/resolve/main/sample_images/{image})\n","      '''\n","    \n","readme_text = f'''---\n","license: creativeml-openrail-m\n","tags:\n","- text-to-image\n","- stable-diffusion\n","---\n","### {Name_of_your_concept} Dreambooth model trained by {api.whoami(token=hf_token)[\"name\"]} with [TheLastBen's fast-DreamBooth](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) notebook\n","\n","\n","Test the concept via A1111 Colab [fast-Colab-A1111](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb)\n","\n","Sample pictures of this concept:\n","{image_string}\n","'''\n","#Save the readme to a file\n","readme_file = open(\"README.md\", \"w\")\n","readme_file.write(readme_text)\n","readme_file.close()\n","\n","operations = [\n","  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n","  CommitOperationAdd(path_in_repo=f\"{Session_Name}.ckpt\",path_or_fileobj=MDLPTH)\n","\n","]\n","create_repo(repo_id,private=True, token=hf_token)\n","\n","api.create_commit(\n","  repo_id=repo_id,\n","  operations=operations,\n","  commit_message=f\"Upload the concept {Name_of_your_concept} embeds and token\",\n","  token=hf_token\n",")\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/feature_extractor\",\n","  path_in_repo=\"feature_extractor\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(4))\n","\n","if NM==\"False\":\n","  api.upload_folder(\n","    folder_path=OUTPUT_DIR+\"/safety_checker\",\n","    path_in_repo=\"safety_checker\",\n","    repo_id=repo_id,\n","    token=hf_token\n","  )\n","\n","clear_output()\n","print(bar(8))\n","\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/scheduler\",\n","  path_in_repo=\"scheduler\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(9))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/text_encoder\",\n","  path_in_repo=\"text_encoder\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(12))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/tokenizer\",\n","  path_in_repo=\"tokenizer\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(13))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/unet\",\n","  path_in_repo=\"unet\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(21))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/vae\",\n","  path_in_repo=\"vae\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(23))\n","\n","api.upload_file(\n","  path_or_fileobj=OUTPUT_DIR+\"/model_index.json\",\n","  path_in_repo=\"model_index.json\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(24))\n","\n","api.upload_folder(\n","  folder_path=Samples,\n","  path_in_repo=\"sample_images\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(25))\n","\n","display_markdown(f'''## Your concept was saved successfully. [Click here to access it](https://huggingface.co/{repo_id})\n","''', raw=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"iVqNi8IDzA1Z"},"outputs":[],"source":["#@markdown #Free Gdrive Space\n","\n","#@markdown Display the list of sessions from your gdrive and choose which ones to remove.\n","\n","import ipywidgets as widgets\n","\n","Sessions=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n","\n","s = widgets.Select(\n","    options=Sessions,\n","    rows=5,\n","    description='',\n","    disabled=False\n",")\n","\n","out=widgets.Output()\n","\n","d = widgets.Button(\n","    description='Remove',\n","    disabled=False,\n","    button_style='warning',\n","    tooltip='Removet the selected session',\n","    icon='warning'\n",")\n","\n","def rem(d):\n","    with out:\n","        if s.value is not None:\n","            clear_output()\n","            print(\"\u001b[1;33mTHE SESSION \u001b[1;31m\"+s.value+\" \u001b[1;33mHAS BEEN REMOVED FROM YOUR GDRIVE\")\n","            !rm -r '/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/{s.value}'\n","            s.options=os.listdir(\"/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")       \n","        else:\n","            d.close()\n","            s.close()\n","            clear_output()\n","            print(\"\u001b[1;32mNOTHING TO REMOVE\")\n","\n","d.on_click(rem)\n","if s.value is not None:\n","    display(s,d,out)\n","else:\n","    print(\"\u001b[1;32mNOTHING TO REMOVE\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["bbKbx185zqlz","AaLtXBbPleBr"],"name":"","provenance":[{"file_id":"https://github.com/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb","timestamp":1680541926999}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0359b9e227f142009f1f322f4dfd2126":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee90f92b73fd400094ad864fae474161","IPY_MODEL_8f8a4afe36ef4b40a2ebebf763f96b6e","IPY_MODEL_4d07b8f357544c4e8c3d6a70f395917f"],"layout":"IPY_MODEL_378f36e1ab4c42b0a237ace2abad88fc"}},"04be873003c044b192de9e2561803bf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"127c799fb12f493ba5b9286db3a4b720":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"120px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"300px"}},"12a84aab4f2f4385940af22867d520c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"Save","disabled":false,"icon":"","layout":"IPY_MODEL_9c71390d1a4b4cd68fcccf7382eb3258","style":"IPY_MODEL_23eec2e643584f03ab01c9bae675a376","tooltip":""}},"146ea88bd14c4fb98946314613fd2102":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_0359b9e227f142009f1f322f4dfd2126"],"layout":"IPY_MODEL_8bb755f9f7b44b8ab8827d1034feeeb8"}},"18d522f09f4b41a08af1e4487f53ecc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SelectModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SelectModel","_options_labels":["Select an instance image to caption","10.jpg","0.jpg","100.jpg","1000.jpg","101.jpg","102.jpg","103.jpg","104.jpg","106.jpg","105.jpg","107.jpg","108.jpg","109.jpg","11.jpg","111.jpg","110.jpg","112.jpg","113.jpg","114.jpg","115.jpg","116.jpg","117.jpg","118.jpg","119.jpg","12.jpg","120.jpg","121.jpg","122.jpg","123.jpg","124.jpg","125.jpg","126.jpg","127.jpg","128.jpg","129.jpg","13.jpg","130.jpg","131.jpg","132.jpg","133.jpg","134.jpg","135.jpg","136.jpg","137.jpg","138.jpg","139.jpg","14.jpg","140.jpg","141.jpg","142.jpg","143.jpg","144.jpg","145.jpg","147.jpg","146.jpg","152.jpg","148.jpg","151.jpg","149.jpg","15.jpg","150.jpg","155.jpg","157.jpg","154.jpg","153.jpg","156.jpg","161.jpg","158.jpg","159.jpg","162.jpg","16.jpg","160.jpg","163.jpg","165.jpg","167.jpg","168.jpg","166.jpg","164.jpg","172.jpg","170.jpg","173.jpg","171.jpg","17.jpg","169.jpg","178.jpg","177.jpg","176.jpg","175.jpg","174.jpg","18.jpg","180.jpg","179.jpg","183.jpg","182.jpg","181.jpg","188.jpg","184.jpg","189.jpg","185.jpg","186.jpg","187.jpg","191.jpg","192.jpg","19.jpg","193.jpg","190.jpg","194.jpg","199.jpg","198.jpg","196.jpg","197.jpg","195.jpg","20.jpg","204.jpg","2.jpg","202.jpg","201.jpg","200.jpg","203.jpg","210.jpg","205.jpg","21.jpg","207.jpg","206.jpg","209.jpg","208.jpg","214.jpg","215.jpg","213.jpg","212.jpg","211.jpg","217.jpg","218.jpg","216.jpg","220.jpg","22.jpg","219.jpg","225.jpg","223.jpg","221.jpg","222.jpg","224.jpg","228.jpg","230.jpg","229.jpg","226.jpg","23.jpg","227.jpg","231.jpg","232.jpg","233.jpg","234.jpg","236.jpg","240.jpg","239.jpg","237.jpg","238.jpg","24.jpg","235.jpg","243.jpg","244.jpg","245.jpg","241.jpg","242.jpg","250.jpg","248.jpg","247.jpg","25.jpg","249.jpg","246.jpg","255.jpg","252.jpg","251.jpg","254.jpg","253.jpg","260.jpg","259.jpg","257.jpg","256.jpg","26.jpg","258.jpg","263.jpg","262.jpg","261.jpg","265.jpg","264.jpg","27.jpg","268.jpg","270.jpg","267.jpg","269.jpg","266.jpg","275.jpg","274.jpg","273.jpg","271.jpg","272.jpg","276.jpg","277.jpg","278.jpg","280.jpg","279.jpg","28.jpg","283.jpg","285.jpg","284.jpg","281.jpg","282.jpg","288.jpg","289.jpg","29.jpg","287.jpg","286.jpg","290.jpg","292.jpg","293.jpg","291.jpg","294.jpg","296.jpg","295.jpg","297.jpg","298.jpg","3.jpg","30.jpg","299.jpg","300.jpg","302.jpg","301.jpg","305.jpg","303.jpg","304.jpg","306.jpg","309.jpg","308.jpg","307.jpg","310.jpg","31.jpg","314.jpg","313.jpg","311.jpg","315.jpg","312.jpg","317.jpg","320.jpg","319.jpg","316.jpg","32.jpg","318.jpg","321.jpg","323.jpg","322.jpg","324.jpg","325.jpg","326.jpg","33.jpg","330.jpg","328.jpg","329.jpg","327.jpg","331.jpg","332.jpg","335.jpg","333.jpg","334.jpg","340.jpg","338.jpg","336.jpg","34.jpg","339.jpg","337.jpg","343.jpg","341.jpg","344.jpg","342.jpg","345.jpg","347.jpg","350.jpg","349.jpg","35.jpg","346.jpg","348.jpg","353.jpg","354.jpg","355.jpg","351.jpg","352.jpg","358.jpg","36.jpg","357.jpg","360.jpg","356.jpg","359.jpg","363.jpg","362.jpg","365.jpg","361.jpg","364.jpg","368.jpg","366.jpg","367.jpg","369.jpg","370.jpg","374.jpg","371.jpg","375.jpg","373.jpg","37.jpg","372.jpg","378.jpg","376.jpg","377.jpg","379.jpg","385.jpg","383.jpg","382.jpg","381.jpg","38.jpg","384.jpg","380.jpg","387.jpg","388.jpg","389.jpg","386.jpg","392.jpg","390.jpg","393.jpg","394.jpg","391.jpg","39.jpg","399.jpg","397.jpg","398.jpg","395.jpg","396.jpg","4.jpg","400.jpg","403.jpg","40.jpg","401.jpg","404.jpg","402.jpg","407.jpg","409.jpg","406.jpg","408.jpg","405.jpg","411.jpg","413.jpg","41.jpg","410.jpg","412.jpg","414.jpg","418.jpg","415.jpg","417.jpg","419.jpg","416.jpg","42.jpg","424.jpg","421.jpg","423.jpg","420.jpg","422.jpg","427.jpg","425.jpg","426.jpg","429.jpg","428.jpg","43.jpg","432.jpg","433.jpg","430.jpg","431.jpg","434.jpg","439.jpg","435.jpg","438.jpg","436.jpg","437.jpg","441.jpg","444.jpg","443.jpg","44.jpg","440.jpg","442.jpg","446.jpg","449.jpg","448.jpg","445.jpg","447.jpg","45.jpg","453.jpg","452.jpg","454.jpg","451.jpg","450.jpg","455.jpg","458.jpg","459.jpg","456.jpg","457.jpg","460.jpg","463.jpg","46.jpg","464.jpg","462.jpg","461.jpg","467.jpg","468.jpg","465.jpg","466.jpg","47.jpg","469.jpg","473.jpg","470.jpg","474.jpg","472.jpg","471.jpg","477.jpg","476.jpg","478.jpg","475.jpg","480.jpg","481.jpg","479.jpg","482.jpg","483.jpg","48.jpg","485.jpg","486.jpg","488.jpg","484.jpg","487.jpg","489.jpg","492.jpg","49.jpg","493.jpg","490.jpg","491.jpg","497.jpg","494.jpg","496.jpg","498.jpg","495.jpg","502.jpg","499.jpg","503.jpg","501.jpg","50.jpg","5.jpg","500.jpg","507.jpg","506.jpg","504.jpg","505.jpg","511.jpg","512.jpg","508.jpg","509.jpg","510.jpg","51.jpg","513.jpg","514.jpg","517.jpg","515.jpg","516.jpg","520.jpg","518.jpg","522.jpg","521.jpg","52.jpg","519.jpg","525.jpg","524.jpg","526.jpg","527.jpg","523.jpg","53.jpg","530.jpg","529.jpg","531.jpg","528.jpg","532.jpg","535.jpg","533.jpg","534.jpg","536.jpg","537.jpg","538.jpg","54.jpg","539.jpg","541.jpg","540.jpg","542.jpg","544.jpg","546.jpg","547.jpg","545.jpg","543.jpg","550.jpg","552.jpg","551.jpg","548.jpg","549.jpg","55.jpg","557.jpg","555.jpg","553.jpg","556.jpg","554.jpg","560.jpg","562.jpg","561.jpg","558.jpg","559.jpg","56.jpg","566.jpg","563.jpg","564.jpg","565.jpg","57.jpg","571.jpg","570.jpg","567.jpg","568.jpg","569.jpg","572.jpg","575.jpg","576.jpg","573.jpg","574.jpg","58.jpg","577.jpg","581.jpg","579.jpg","580.jpg","578.jpg","582.jpg","584.jpg","585.jpg","583.jpg","586.jpg","587.jpg","589.jpg","59.jpg","590.jpg","588.jpg","591.jpg","593.jpg","592.jpg","594.jpg","595.jpg","599.jpg","598.jpg","60.jpg","601.jpg","6.jpg","596.jpg","597.jpg","600.jpg","603.jpg","602.jpg","605.jpg","604.jpg","608.jpg","610.jpg","61.jpg","609.jpg","607.jpg","606.jpg","612.jpg","614.jpg","613.jpg","615.jpg","611.jpg","616.jpg","617.jpg","618.jpg","62.jpg","620.jpg","619.jpg","621.jpg","623.jpg","624.jpg","622.jpg","63.jpg","627.jpg","628.jpg","630.jpg","625.jpg","626.jpg","629.jpg","633.jpg","632.jpg","634.jpg","631.jpg","639.jpg","638.jpg","635.jpg","637.jpg","636.jpg","644.jpg","64.jpg","640.jpg","643.jpg","642.jpg","641.jpg","645.jpg","647.jpg","646.jpg","649.jpg","648.jpg","652.jpg","650.jpg","65.jpg","654.jpg","651.jpg","653.jpg","655.jpg","658.jpg","656.jpg","659.jpg","657.jpg","664.jpg","661.jpg","66.jpg","660.jpg","663.jpg","662.jpg","669.jpg","666.jpg","667.jpg","668.jpg","665.jpg","674.jpg","675.jpg","672.jpg","673.jpg","671.jpg","67.jpg","670.jpg","676.jpg","677.jpg","679.jpg","678.jpg","683.jpg","681.jpg","684.jpg","680.jpg","682.jpg","68.jpg","685.jpg","689.jpg","686.jpg","688.jpg","687.jpg","692.jpg","690.jpg","693.jpg","691.jpg","694.jpg","69.jpg","699.jpg","698.jpg","7.jpg","696.jpg","697.jpg","70.jpg","695.jpg","704.jpg","701.jpg","703.jpg","700.jpg","702.jpg","708.jpg","705.jpg","709.jpg","706.jpg","707.jpg","71.jpg","713.jpg","711.jpg","714.jpg","710.jpg","712.jpg","715.jpg","717.jpg","718.jpg","716.jpg","719.jpg","723.jpg","721.jpg","720.jpg","724.jpg","72.jpg","722.jpg","726.jpg","725.jpg","727.jpg","728.jpg","729.jpg","733.jpg","734.jpg","731.jpg","732.jpg","73.jpg","730.jpg","736.jpg","738.jpg","737.jpg","735.jpg","739.jpg","744.jpg","74.jpg","742.jpg","741.jpg","740.jpg","743.jpg","748.jpg","746.jpg","745.jpg","747.jpg","749.jpg","753.jpg","751.jpg","752.jpg","754.jpg","750.jpg","75.jpg","756.jpg","758.jpg","755.jpg","759.jpg","757.jpg","763.jpg","761.jpg","76.jpg","760.jpg","762.jpg","764.jpg","767.jpg","765.jpg","769.jpg","768.jpg","766.jpg","772.jpg","774.jpg","773.jpg","770.jpg","77.jpg","771.jpg","776.jpg","775.jpg","777.jpg","779.jpg","778.jpg","782.jpg","780.jpg","783.jpg","784.jpg","781.jpg","78.jpg","789.jpg","785.jpg","788.jpg","787.jpg","786.jpg","791.jpg","79.jpg","793.jpg","790.jpg","792.jpg","794.jpg","806.jpg","797.jpg","803.jpg","808.jpg","816.jpg","801.jpg","810.jpg","804.jpg","802.jpg","798.jpg","812.jpg","8.jpg","81.jpg","805.jpg","795.jpg","815.jpg","799.jpg","80.jpg","811.jpg","807.jpg","814.jpg","796.jpg","809.jpg","800.jpg","813.jpg","85.jpg","825.jpg","820.jpg","857.jpg","831.jpg","847.jpg","859.jpg","86.jpg","836.jpg","83.jpg","844.jpg","846.jpg","845.jpg","862.jpg","838.jpg","829.jpg","863.jpg","858.jpg","843.jpg","860.jpg","851.jpg","827.jpg","850.jpg","830.jpg","861.jpg","849.jpg","822.jpg","823.jpg","819.jpg","835.jpg","824.jpg","817.jpg","855.jpg","839.jpg","864.jpg","854.jpg","818.jpg","833.jpg","852.jpg","840.jpg","842.jpg","821.jpg","84.jpg","82.jpg","856.jpg","826.jpg","832.jpg","848.jpg","853.jpg","828.jpg","834.jpg","837.jpg","841.jpg","872.jpg","91.jpg","868.jpg","909.jpg","9.jpg","898.jpg","886.jpg","908.jpg","873.jpg","867.jpg","896.jpg","914.jpg","877.jpg","875.jpg","885.jpg","884.jpg","893.jpg","871.jpg","882.jpg","894.jpg","883.jpg","866.jpg","897.jpg","892.jpg","89.jpg","865.jpg","890.jpg","90.jpg","895.jpg","912.jpg","910.jpg","899.jpg","88.jpg","880.jpg","913.jpg","907.jpg","889.jpg","881.jpg","900.jpg","902.jpg","874.jpg","901.jpg","888.jpg","879.jpg","904.jpg","876.jpg","906.jpg","903.jpg","905.jpg","870.jpg","891.jpg","87.jpg","887.jpg","878.jpg","869.jpg","911.jpg","915.jpg","93.jpg","948.jpg","931.jpg","924.jpg","949.jpg","920.jpg","956.jpg","947.jpg","92.jpg","927.jpg","945.jpg","942.jpg","938.jpg","934.jpg","930.jpg","929.jpg","916.jpg","941.jpg","943.jpg","918.jpg","917.jpg","935.jpg","922.jpg","94.jpg","958.jpg","936.jpg","937.jpg","944.jpg","957.jpg","950.jpg","925.jpg","933.jpg","952.jpg","946.jpg","919.jpg","928.jpg","940.jpg","954.jpg","951.jpg","939.jpg","921.jpg","923.jpg","926.jpg","959.jpg","95.jpg","960.jpg","96.jpg","955.jpg","932.jpg","953.jpg","977.jpg","996.jpg","986.jpg","974.jpg","964.jpg","975.jpg","966.jpg","999.jpg","965.jpg","979.jpg","988.jpg","987.jpg","972.jpg","98.jpg","998.jpg","968.jpg","961.jpg","99.jpg","976.jpg","97.jpg","991.jpg","992.jpg","994.jpg","984.jpg","997.jpg","962.jpg","971.jpg","980.jpg","967.jpg","995.jpg","985.jpg","989.jpg","963.jpg","973.jpg","969.jpg","983.jpg","970.jpg","981.jpg","982.jpg","990.jpg","978.jpg","993.jpg","1.jpg"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"SelectView","description":"","description_tooltip":null,"disabled":false,"index":2,"layout":"IPY_MODEL_5d88311281f94915b83d7c6a32b36fdf","rows":25,"style":"IPY_MODEL_2d18b0b4c9a34775b39f5da55a431a4c"}},"23eec2e643584f03ab01c9bae675a376":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"251c6e3b177442c9b53d31cfa4a36c91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d18b0b4c9a34775b39f5da55a431a4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"378f36e1ab4c42b0a237ace2abad88fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d07b8f357544c4e8c3d6a70f395917f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"Save","disabled":false,"icon":"","layout":"IPY_MODEL_f2bb16d3ffa64d5796db81dd45594811","style":"IPY_MODEL_04be873003c044b192de9e2561803bf7","tooltip":""}},"5c2a7fac54e7435398da0a2ad4f79ee3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d88311281f94915b83d7c6a32b36fdf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f397cb14a3e4861bc06e67b96ac1620":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_718a3abfd8dd412da92fea55c49d0130","IPY_MODEL_c8b31fbe9c04400bacfc3244ede892d7","IPY_MODEL_12a84aab4f2f4385940af22867d520c3"],"layout":"IPY_MODEL_5c2a7fac54e7435398da0a2ad4f79ee3"}},"71331e0ee9994e7d82b4ee2c04a12ac8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"120px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"300px"}},"718a3abfd8dd412da92fea55c49d0130":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ImageModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ImageModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ImageView","format":"png","height":"420","layout":"IPY_MODEL_8943b7c267eb46259014929559c9b18a","width":"420"}},"7c8c1c021cae4719a0cf1037a2352433":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8943b7c267eb46259014929559c9b18a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bb755f9f7b44b8ab8827d1034feeeb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f8a4afe36ef4b40a2ebebf763f96b6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"TextareaModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_71331e0ee9994e7d82b4ee2c04a12ac8","placeholder":"​","rows":null,"style":"IPY_MODEL_eb06a13f6fa74be9a0942328425f2f75","value":""}},"9c71390d1a4b4cd68fcccf7382eb3258":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a62d78c66af446a4b6111e741dde64f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aba18f6392e64d44b63cbb7bd82e3b36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea14c429e6242f798162754a5617a3c":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_ef995090b3c248f2bcaebe6376d3e50f","msg_id":"","outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3f33d4a4e3e4fe9a9bcfe766f77047e","version_major":2,"version_minor":0},"text/plain":"VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x…"},"metadata":{},"output_type":"display_data"}]}},"bfcd9b831a4d46e88fca6e8b33ce572e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18d522f09f4b41a08af1e4487f53ecc9","IPY_MODEL_aea14c429e6242f798162754a5617a3c"],"layout":"IPY_MODEL_a62d78c66af446a4b6111e741dde64f3"}},"c3f33d4a4e3e4fe9a9bcfe766f77047e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5f397cb14a3e4861bc06e67b96ac1620"],"layout":"IPY_MODEL_7c8c1c021cae4719a0cf1037a2352433"}},"c8b31fbe9c04400bacfc3244ede892d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"TextareaModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextareaModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextareaView","continuous_update":true,"description":"","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_127c799fb12f493ba5b9286db3a4b720","placeholder":"​","rows":null,"style":"IPY_MODEL_251c6e3b177442c9b53d31cfa4a36c91","value":""}},"eb06a13f6fa74be9a0942328425f2f75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee90f92b73fd400094ad864fae474161":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ImageModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ImageModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ImageView","format":"png","height":"420","layout":"IPY_MODEL_aba18f6392e64d44b63cbb7bd82e3b36","width":"420"}},"ef995090b3c248f2bcaebe6376d3e50f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2bb16d3ffa64d5796db81dd45594811":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}